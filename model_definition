import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv
from torch_geometric.utils import k_hop_subgraph

class MultiScaleGATv2_LSTM(nn.Module):
    def __init__(self, node_feature_dim, sequence_feature_dim, gat_out_channels, gat_heads,
                 lstm_hidden_dim, lstm_layers, edge_dim, forecast_horizon, reduced_dim=32):
        super(MultiScaleGATv2_LSTM, self).__init__()

        # 1-Hop Branch
        self.gat_1hop = GATv2Conv(node_feature_dim, gat_out_channels, heads=gat_heads, 
                                  concat=False, edge_dim=edge_dim)
        # 2-Hop Branch
        self.gat_2hop_1 = GATv2Conv(node_feature_dim, gat_out_channels, heads=gat_heads, 
                                    concat=False, edge_dim=edge_dim)
        self.gat_2hop_2 = GATv2Conv(gat_out_channels, gat_out_channels, heads=gat_heads,
                                    concat=False, edge_dim=edge_dim)
        self.gat_dropout = nn.Dropout(0.2)
        self.layer_norm = nn.LayerNorm(2 * gat_out_channels)
        self.graph_projection = nn.Linear(2 * gat_out_channels, reduced_dim)
        
        # LSTM input: concatenated dynamic sequence and static graph embedding.
        combined_input_dim = sequence_feature_dim + reduced_dim
        self.lstm = nn.LSTM(combined_input_dim, lstm_hidden_dim, num_layers=lstm_layers,
                            batch_first=True, dropout=0.3)
        self.fc = nn.Linear(lstm_hidden_dim, forecast_horizon)
        
        # Buffer for precomputed static graph embeddings.
        self.register_buffer("precomputed_embeddings", None)

    def precompute_embeddings(self, node_features, edge_index, edge_attr, node_indices):
        # 1-Hop branch
        one_hop_out = self.gat_dropout(self.gat_1hop(node_features, edge_index, edge_attr))
        one_hop_out = one_hop_out[node_indices]
        # 2-Hop branch via k-hop subgraph.
        subset, edge_index_2hop, mapping, edge_mask = k_hop_subgraph(
            node_indices, 2, edge_index, num_nodes=node_features.size(0),
            relabel_nodes=True, flow='source_to_target'
        )
        edge_attr_2hop = edge_attr[edge_mask]
        two_hop_intermediate = self.gat_dropout(self.gat_2hop_1(node_features, edge_index_2hop, edge_attr_2hop))
        two_hop_out = self.gat_dropout(self.gat_2hop_2(two_hop_intermediate, edge_index_2hop, edge_attr_2hop))
        two_hop_out = two_hop_out[mapping]
        # Fuse features.
        multiscale_features = torch.cat((one_hop_out, two_hop_out), dim=-1)
        multiscale_features = self.layer_norm(multiscale_features)
        multiscale_features = self.graph_projection(multiscale_features)
        self.precomputed_embeddings = multiscale_features.detach()

    def forward(self, sequences, nodes):
        if self.precomputed_embeddings is None:
            raise ValueError("Precomputed embeddings not available. Call precompute_embeddings() first.")
        embeddings = self.precomputed_embeddings[nodes]
        batch, T, _ = sequences.shape
        if embeddings.shape[0] != batch:
            raise ValueError(f"Batch size ({batch}) does not match number of embeddings ({embeddings.shape[0]}).")
        multiscale_expanded = embeddings.unsqueeze(1).repeat(1, T, 1)
        combined_input = torch.cat((sequences, multiscale_expanded), dim=-1)
        lstm_out, _ = self.lstm(combined_input)
        output = self.fc(lstm_out[:, -1, :])
        return output
